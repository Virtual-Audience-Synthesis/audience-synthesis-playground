{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np \n",
    "from multiprocessing import Pool\n",
    "import time \n",
    "import random\n",
    "import IPython.display as ipd\n",
    "import pyaudio\n",
    "import librosa\n",
    "import librosa.display\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    sys.path.append(str(Path().cwd().parent.parent))\n",
    "    sys.path.append(str(Path().cwd()))\n",
    "except IndexError:\n",
    "    pass\n",
    "\n",
    "#import utils.audio as a\n",
    "#import utils.plots as plots\n",
    "import utils as utils\n",
    "\n",
    "utils.misc.change_docker_cwd(\"./synthesizer/full_audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load (fe)male audio sequences without alpha, beta \n",
    "female_audios = np.load(\"female_audios/female_audios_500.npy\")\n",
    "male_audios = np.load(\"male_audios/male_audios_500.npy\")\n",
    "\n",
    "N = 1000\n",
    "ratio = 0.5\n",
    "n_male = int(ratio * N)\n",
    "n_female = N - n_male\n",
    "SR = 22050 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get male indices and audio signals\n",
    "male_idx = np.random.choice(male_audios.shape[0], n_male)\n",
    "males = [male_audios[i] for i in male_idx]\n",
    "\n",
    "# get female indices and audio signals\n",
    "female_idx = np.random.choice(female_audios.shape[0], n_female)\n",
    "females = [female_audios[i] for i in female_idx]\n",
    "\n",
    "# concatenate both lists and shuffle\n",
    "mixed_audio = np.array(random.sample(males+females, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data = utils.misc.slidingWindow(mixed_audio, int(SR*1), int(SR*1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librosa\n",
    "inp = data[np.random.randint(1000), np.random.randint(10)]\n",
    "mfccs = librosa.feature.mfcc(y=inp, sr=SR, n_mfcc=20) #has quite a bunch of parameters\n",
    "librosa.display.specshow(mfccs, sr=SR, x_axis='time')\n",
    "ipd.Audio(inp, rate=SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 1000\n",
    "num_feats = 6\n",
    "num_chunks = 10\n",
    "X = np.zeros((num_points*num_chunks, 44*num_feats))\n",
    "for i in range(num_points):\n",
    "    for j in range(num_chunks):\n",
    "        X[i*num_chunks+j, :] = librosa.feature.mfcc(y=data[i, j], sr=SR, n_mfcc=num_feats).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "new_X = StandardScaler().fit_transform(X)\n",
    "\n",
    "#new_X = X\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "pca_X = pca.fit_transform(new_X)\n",
    "\n",
    "#pca_X = new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = GaussianMixture(n_components=6).fit(pca_X)\n",
    "labels = gmm.predict(pca_X)\n",
    "plt.hist(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 3\n",
    "idx = np.where(labels==target)[0][0]\n",
    "print(labels[idx])\n",
    "i = idx // num_chunks\n",
    "j = idx % num_chunks\n",
    "ipd.Audio(data[i, j], rate=SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(labels==target)[0][1]\n",
    "print(labels[idx])\n",
    "i = idx // num_chunks\n",
    "j = idx % num_chunks\n",
    "ipd.Audio(data[i, j], rate=SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(labels==target)[0][2]\n",
    "print(labels[idx])\n",
    "i = idx // num_chunks\n",
    "j = idx % num_chunks\n",
    "ipd.Audio(data[i, j], rate=SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(labels==target)[0][3]\n",
    "print(labels[idx])\n",
    "i = idx // num_chunks\n",
    "j = idx % num_chunks\n",
    "ipd.Audio(data[i, j], rate=SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(labels==target)[0][4]\n",
    "print(labels[idx])\n",
    "i = idx // num_chunks\n",
    "j = idx % num_chunks\n",
    "ipd.Audio(data[i, j], rate=SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "plot_X = PCA(n_components=3).fit_transform(pca_X)\n",
    "colors = ['r', 'b', 'g', 'm', 'k', 'c']\n",
    "fig = plt.figure(figsize=[10, 5])\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for i in range(6):\n",
    "    ax.scatter(plot_X[labels==i, 0], plot_X[labels==i, 1], plot_X[labels==i, 2], c=colors[i], s=.1);\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}