{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np \n",
    "import time \n",
    "import random\n",
    "import IPython.display as ipd\n",
    "import pyaudio\n",
    "import sys\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import soundfile as sf\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "import pdb\n",
    "#import utils.audio as a\n",
    "#import utils.plots as plots\n",
    "import utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 383/383 [00:00<00:00, 704.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((383,), (51237,), (383,), (46, 2205))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load (fe)male audio sequences without alpha, beta \n",
    "PATH = '../../datasets/freesound.org/wav/'\n",
    "SR = 22050 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "train = False\n",
    "\n",
    "if train:\n",
    "    #X_scaled = MinMaxScaler(feature_range=(0, 1)).fit_transform(X)\n",
    "    X_scaled = chunk_feat_vec.reshape(chunk_feat_vec.shape[0], -1)\n",
    "    #x_pca = PCA(n_components=2).fit_transform(X_scaled)\n",
    "    np.random.seed(42)\n",
    "    #model = hmm.GaussianHMM(n_components=3, covariance_type=\"diagonal\", n_iter=100)\n",
    "    model = hmm.GaussianHMM(n_components=3, verbose=True, covariance_type=\"full\", n_iter=100)\n",
    "    #model.fit(np.array(x_pca), len_vec)\n",
    "    model.fit(np.array(X_scaled), len_vec)\n",
    "\n",
    "    with open(\"hmm_feat_20_100ms.pkl\", \"wb\") as file: pickle.dump(model, file)\n",
    "else:\n",
    "    with open(\"hmm_feat_20_100ms.pkl\", \"rb\") as file: model = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 383/383 [03:02<00:00,  2.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# load (fe)male audio sequences without alpha, beta \n",
    "PATH = '../../datasets/freesound.org/'\n",
    "SR = 22050 \n",
    "\n",
    "dataset = []\n",
    "chunk_sz = int(SR * .1) # 100ms\n",
    "num_feats = 6\n",
    "files = os.listdir(PATH + \"wav/\")\n",
    "X = []\n",
    "for f in tqdm(files):\n",
    "    if f.split('.')[-1] != 'wav':\n",
    "        continue\n",
    "    #pdb.set_trace()\n",
    "    audio, sr = utils.audio.loadAudio(PATH + \"wav/\" + f, sr=SR)\n",
    "    chunks = utils.misc.slidingWindow(audio, chunk_sz, chunk_sz)\n",
    "    X = []\n",
    "    \n",
    "    for i, (chunk) in enumerate(chunks):\n",
    "         # mfcc\n",
    "        feat = librosa.feature.mfcc(y=chunks[i, :], sr=SR, n_mfcc=num_feats).flatten() # 13x44\n",
    "\n",
    "        # RMS mag spec\n",
    "        rms = librosa.feature.rms(y=chunks[i, :]).flatten() #1x44\n",
    "\n",
    "        # Spectral centroid\n",
    "        cent = librosa.feature.spectral_centroid(y=chunks[i, :], sr=SR).flatten()#1x44\n",
    "\n",
    "        # Spectral bandwidth\n",
    "        band = librosa.feature.spectral_bandwidth(y=chunks[i, :], sr=SR).flatten()#1x44\n",
    "\n",
    "        # Spectral flatness\n",
    "        flat = librosa.feature.spectral_flatness(y=chunks[i, :]).flatten()#1x44\n",
    "\n",
    "        # spectral rolloff\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=chunks[i, :], sr=SR).flatten()#1x44\n",
    "\n",
    "        # zero crossing rate \n",
    "        zcross = librosa.feature.zero_crossing_rate(chunks[i, :]).flatten()#1x44\n",
    "\n",
    "        # Spectral contrast\n",
    "        S = np.abs(librosa.stft(chunks[i, :]))\n",
    "        spec_contrast = librosa.feature.spectral_contrast(S=S, sr=SR).flatten() #7x44\n",
    "        \n",
    "        # concetante to feature vector\n",
    "        X.append(np.concatenate((feat, rms, cent, band, flat, rolloff, zcross, spec_contrast)))\n",
    "        \n",
    "    audio_denoised = utils.audio.removeNoise(model, 0, chunk_sz, np.asarray(X), audio)    \n",
    "        #print(np.asarray(X).reshape(-1).shape)\n",
    "        #pdb.set_trace()\n",
    "    #np.save(PATH + \"wav_denoised/\" + f, audio_denoised)\n",
    "    sf.write(PATH + \"wav_denoised/\" + f, audio_denoised, SR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
